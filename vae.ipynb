{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seven Three Five  Zero \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ('Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven', 'Eight', 'Nine')\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(x_reconstructed, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(x_reconstructed, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        reconstructed_x, mu, log_var = model(data)\n",
    "        loss = loss_function(reconstructed_x, data, mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "            print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "            r_x, mu, log_var = model(data)\n",
    "            test_loss += loss_function(r_x, data, mu, log_var)\n",
    "        \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('====> Test set loss: {:.4f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder 1x28x28\n",
    "        self.conv1 = nn.Conv2d(1, 1, 3, padding=0) #1x26x26\n",
    "        self.conv2 = nn.Conv2d(1, 1, 3, padding=0) #1x24x24\n",
    "        self.conv3 = nn.Conv2d(1, 1, 5, padding=0) # 1x20x20\n",
    "        self.conv4 = nn.Conv2d(1, 1, 5, padding=0) #1x16x16\n",
    "\n",
    "        # Latent\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc21 = nn.Linear(128, 64)\n",
    "        self.fc22 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Decoder 1x64\n",
    "        self.fc3 = nn.Linear(64, 128) # 1x128\n",
    "        self.fc4 = nn.Linear(128, 256) # 1x256\n",
    "        self.conv5 = nn.Conv2d(1, 1, 3, padding=2) # 1x18x18\n",
    "        self.conv6 = nn.Conv2d(1, 1, 3, padding=2) # 1x20x20\n",
    "        self.conv7 = nn.Conv2d(1, 1, 3, padding=3) # 1x24x24\n",
    "        self.conv8 = nn.Conv2d(1, 1, 3, padding=3) # 1x28x28\n",
    "\n",
    "    def encoder(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))    \n",
    "\n",
    "        x_flat = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x_flat)\n",
    "\n",
    "        return self.fc21(x), self.fc22(x) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # 1x\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "\n",
    "        x = x.view(-1, 1, 16, 16)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "\n",
    "        return F.sigmoid(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x)\n",
    "        latent_z = self.sampling(mu, log_var)\n",
    "        return self.decoder(latent_z), mu, log_var\n",
    "    \n",
    "    \n",
    "vae = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 543.582764\n",
      "====> Epoch: 1 Average loss: 0.0362\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 36.2648\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 72.4933\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 108.7218\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 144.9503\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 181.1788\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 217.4073\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 253.6358\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 289.8642\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 326.0927\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 362.3212\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 398.5497\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 434.7782\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 471.0067\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 543.427429\n",
      "====> Epoch: 1 Average loss: 507.2352\n",
      "====> Test set loss: 543.4208\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 0.0362\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 36.2647\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 72.4932\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 108.7217\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 144.9502\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 181.1787\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 217.4072\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 253.6357\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 289.8642\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 326.0927\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 362.3212\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 398.5497\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 434.7782\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 471.0067\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 543.427429\n",
      "====> Epoch: 2 Average loss: 507.2352\n",
      "====> Test set loss: 543.4208\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 0.0362\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 36.2647\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 72.4932\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 108.7217\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 144.9502\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 181.1787\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 217.4072\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 253.6357\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 289.8642\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 326.0927\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 362.3212\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 398.5497\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 434.7782\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 471.0067\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 543.427429\n",
      "====> Epoch: 3 Average loss: 507.2352\n",
      "====> Test set loss: 543.4208\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 543.427429\n",
      "====> Epoch: 4 Average loss: 0.0362\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 543.427429\n",
      "====> Epoch: 4 Average loss: 36.2647\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 543.427429\n",
      "====> Epoch: 4 Average loss: 72.4932\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 543.427429\n",
      "====> Epoch: 4 Average loss: 108.7217\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5):\n",
    "    train(epoch, vae, optimizer)\n",
    "    test(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
